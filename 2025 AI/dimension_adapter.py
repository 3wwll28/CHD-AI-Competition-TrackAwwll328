# dimension_adapter.py - ä¿®å¤ç‰ˆæœ¬
import torch
import torch.nn as nn
import torch.nn.functional as F

class CompetitionDimensionAdapter:
    """æ¯”èµ›ä¸“ç”¨ç»´åº¦é€‚é…å™¨ - ç¡®ä¿æ‰€æœ‰æ¨¡å—å…¼å®¹"""
    
    def __init__(self, hidden_dim=256):
        self.hidden_dim = hidden_dim
        self.adapters = {}
        print(f"ğŸ”§ åˆå§‹åŒ–æ¯”èµ›ç»´åº¦é€‚é…å™¨: ç›®æ ‡ç»´åº¦={hidden_dim}")
    
    def adapt_visual_features(self, visual_features):
        """é€‚é…è§†è§‰ç‰¹å¾ç»´åº¦"""
        adapted_features = []
        for i, feat in enumerate(visual_features):
            print(f"      ğŸ”§ é€‚é…è§†è§‰ç‰¹å¾å°ºåº¦ {i}: {feat.shape}")
            
            # ç¡®ä¿é€šé“æ•°ä¸º256
            if feat.shape[1] != self.hidden_dim:
                adapter = nn.Conv2d(feat.shape[1], self.hidden_dim, 1)
                adapter = adapter.to(feat.device)
                adapted_feat = adapter(feat)
                print(f"         âœ… é€šé“æ•°é€‚é…: {feat.shape[1]} -> {self.hidden_dim}")
            else:
                adapted_feat = feat
            
            adapted_features.append(adapted_feat)
        
        return adapted_features
    
    def adapt_text_features(self, text_features):
        """é€‚é…æ–‡æœ¬ç‰¹å¾ç»´åº¦"""
        if isinstance(text_features, dict):
            features = text_features['features']
            mask = text_features['mask']
        else:
            features, mask = text_features
            
        print(f"      ğŸ”§ é€‚é…æ–‡æœ¬ç‰¹å¾: {features.shape}")
        
        # ç¡®ä¿æ–‡æœ¬ç‰¹å¾ç»´åº¦ä¸º256
        if features.shape[-1] != self.hidden_dim:
            adapter = nn.Linear(features.shape[-1], self.hidden_dim)
            adapter = adapter.to(features.device)
            adapted_features = adapter(features)
            print(f"         âœ… æ–‡æœ¬ç»´åº¦é€‚é…: {features.shape[-1]} -> {self.hidden_dim}")
        else:
            adapted_features = features
            
        return {'features': adapted_features, 'mask': mask}
    
    def adapt_depth_features(self, depth_features):
        """é€‚é…æ·±åº¦ç‰¹å¾ç»´åº¦"""
        print(f"      ğŸ”§ é€‚é…æ·±åº¦ç‰¹å¾: {depth_features.shape}")
        
        if depth_features.shape[1] != self.hidden_dim:
            # æ·±åº¦ç‰¹å¾é€šå¸¸æ˜¯ [batch, frames, channels, H, W]
            batch, frames, channels, H, W = depth_features.shape
            depth_flat = depth_features.view(batch * frames, channels, H, W)
            
            adapter = nn.Conv2d(channels, self.hidden_dim, 1)
            adapter = adapter.to(depth_features.device)
            adapted_flat = adapter(depth_flat)
            
            adapted_features = adapted_flat.view(batch, frames, self.hidden_dim, H, W)
            print(f"         âœ… æ·±åº¦ç»´åº¦é€‚é…: {channels} -> {self.hidden_dim}")
        else:
            adapted_features = depth_features
            
        return adapted_features

    def adapt_lmttm_input(self, input_tensor):
        """é€‚é…LMTTMè¾“å…¥"""
        print(f"      ğŸ”§ é€‚é…LMTTMè¾“å…¥: {input_tensor.shape}")
        
        if input_tensor.dim() == 3:
            # [batch, tokens, features] -> [batch, 1, tokens, features]
            input_tensor = input_tensor.unsqueeze(1)
            print(f"         âœ… 3ç»´è½¬4ç»´: {input_tensor.shape}")
        elif input_tensor.dim() == 4:
            # æ£€æŸ¥å½¢çŠ¶ [batch, sequence, tokens, features]
            batch, seq, tokens, features = input_tensor.shape
            if features != self.hidden_dim:
                # éœ€è¦è°ƒæ•´ç‰¹å¾ç»´åº¦
                input_tensor = input_tensor.reshape(batch * seq * tokens, features)
                adapter = nn.Linear(features, self.hidden_dim)
                adapter = adapter.to(input_tensor.device)
                adapted = adapter(input_tensor)
                input_tensor = adapted.reshape(batch, seq, tokens, self.hidden_dim)
                print(f"         âœ… ç‰¹å¾ç»´åº¦é€‚é…: {features} -> {self.hidden_dim}")
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„LMTTMè¾“å…¥ç»´åº¦: {input_tensor.dim()}")
            
        return input_tensor

# å…¨å±€é€‚é…å™¨å®ä¾‹
competition_adapter = CompetitionDimensionAdapter(256)