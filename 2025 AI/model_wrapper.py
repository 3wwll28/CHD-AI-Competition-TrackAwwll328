# model_wrapper.py - åˆ›å»ºæ–°æ–‡ä»¶æ¥åŒ…è£…å­¦æ ¡æ¨¡å‹
import torch
import torch.nn as nn

class SafeModelWrapper(nn.Module):
    """å®‰å…¨æ¨¡å‹åŒ…è£…å™¨ï¼Œå¤„ç†æ‰€æœ‰ç»´åº¦é—®é¢˜"""
    
    def __init__(self, original_model, hidden_dim=256):
        super().__init__()
        self.original_model = original_model
        self.hidden_dim = hidden_dim
        
        # ç»´åº¦é€‚é…å™¨
        from dimension_adapter import DimensionAdapter
        self.dimension_adapter = DimensionAdapter
        
        # æ–‡æœ¬ç‰¹å¾é€‚é…å™¨
        self.text_adapter = nn.Linear(768, hidden_dim)
        
    def forward(self, srcs, masks, pos_embeds, query_embed=None, depth_pos_embed=None,
                text_memory=None, text_mask=None, im_name=None, instanceID=None, ann_id=None):
        
        print("      ğŸ›¡ï¸ å®‰å…¨æ¨¡å‹åŒ…è£…å™¨å¼€å§‹å¤„ç†...")
        
        try:
            # é€‚é…æ–‡æœ¬ç‰¹å¾ç»´åº¦
            if text_memory is not None and text_memory.shape[-1] != self.hidden_dim:
                print(f"      ğŸ”§ é€‚é…æ–‡æœ¬ç‰¹å¾: {text_memory.shape} -> {self.hidden_dim}")
                text_memory = self.text_adapter(text_memory)
            
            # é€‚é…æ·±åº¦ä½ç½®ç¼–ç 
            if depth_pos_embed is not None:
                depth_batch, depth_seq, depth_dim = depth_pos_embed.shape
                if depth_dim != self.hidden_dim:
                    print(f"      ğŸ”§ é€‚é…æ·±åº¦ä½ç½®ç¼–ç : {depth_pos_embed.shape}")
                    depth_pos_embed = depth_pos_embed.view(depth_batch * depth_seq, depth_dim)
                    depth_pos_embed = self.dimension_adapter.adapt_features(depth_pos_embed, self.hidden_dim)
                    depth_pos_embed = depth_pos_embed.view(depth_batch, depth_seq, self.hidden_dim)
            
            # è°ƒç”¨åŸå§‹æ¨¡å‹
            outputs = self.original_model(
                srcs=srcs,
                masks=masks,
                pos_embeds=pos_embeds,
                query_embed=query_embed,
                depth_pos_embed=depth_pos_embed,
                text_memory=text_memory,
                text_mask=text_mask,
                im_name=im_name,
                instanceID=instanceID,
                ann_id=ann_id
            )
            
            print("      âœ… å®‰å…¨æ¨¡å‹åŒ…è£…å™¨å®Œæˆ")
            return outputs
            
        except Exception as e:
            print(f"      ğŸ”´ å®‰å…¨æ¨¡å‹åŒ…è£…å™¨å¤±è´¥: {e}")
            # è¿”å›å®‰å…¨çš„æ¨¡æ‹Ÿè¾“å‡º
            batch_size = srcs[0].shape[0] if srcs else 1
            hs = torch.randn(batch_size, 1, self.hidden_dim)
            reference_points = torch.randn(batch_size, 1, 2)
            return hs, reference_points, None, None, None, None

def wrap_school_model(original_model, hidden_dim=256):
    """åŒ…è£…å­¦æ ¡æä¾›çš„æ¨¡å‹"""
    return SafeModelWrapper(original_model, hidden_dim)